"""
ğŸ¯ ì±—ë´‡ ì„œë¹„ìŠ¤ - êµ¬í˜„ íŒŒì¼

ì´ íŒŒì¼ì€ ì±—ë´‡ì˜ í•µì‹¬ AI ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì•„ë˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ì„¸ìš”.

ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ì´ˆê¸°í™” ë‹¨ê³„ (ChatbotService.__init__)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - OpenAI Client ìƒì„±                                    â”‚
â”‚  - ChromaDB ì—°ê²° (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)                       â”‚
â”‚  - LangChain Memory ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)               â”‚
â”‚  - Config íŒŒì¼ ë¡œë“œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAG íŒŒì´í”„ë¼ì¸ (generate_response ë‚´ë¶€)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ì‚¬ìš©ì ì§ˆë¬¸ "í•™ì‹ ì¶”ì²œí•´ì¤˜"                              â”‚
â”‚       â†“                                                  â”‚
â”‚  [_create_embedding()]                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  ì§ˆë¬¸ ë²¡í„°: [0.12, -0.34, ..., 0.78]  (3072ì°¨ì›)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_search_similar()]  â† ChromaDB ê²€ìƒ‰                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ê²€ìƒ‰ ê²°ê³¼: "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´" (ìœ ì‚¬ë„: 0.87)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_build_prompt()]                                       â”‚
â”‚       â†“                                                  â”‚
â”‚  ìµœì¢… í”„ë¡¬í”„íŠ¸ = ì‹œìŠ¤í…œ ì„¤ì • + RAG ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ì‘ë‹µ ìƒì„±                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI GPT-4 API í˜¸ì¶œ                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì œì¼ ì¢‹ì•„! ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼"    â”‚
â”‚       â†“                                                  â”‚
â”‚  [ì„ íƒ: ì´ë¯¸ì§€ ê²€ìƒ‰]                                      â”‚
â”‚       â†“                                                  â”‚
â”‚  ì‘ë‹µ ë°˜í™˜: {reply: "...", image: "..."}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ë©”ëª¨ë¦¬ ì €ì¥ (LangChain Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸-ì‘ë‹µ ì €ì¥                               â”‚
â”‚  ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ’¡ í•µì‹¬ êµ¬í˜„ ê³¼ì œ:

1. **Embedding ìƒì„±**
   - OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
   - ëª¨ë¸: text-embedding-3-large (3072ì°¨ì›)

2. **RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** â­ ê°€ì¥ ì¤‘ìš”!
   - ChromaDBì—ì„œ ìœ ì‚¬ ë²¡í„° ê²€ìƒ‰
   - ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
   - threshold ì´ìƒì¸ ë¬¸ì„œë§Œ ì„ íƒ

3. **LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„**
   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
   - RAG ì»¨í…ìŠ¤íŠ¸ í†µí•©
   - ëŒ€í™” ê¸°ë¡ í¬í•¨

4. **ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - LangChainì˜ ConversationSummaryBufferMemory ì‚¬ìš©
   - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½


ğŸ“š ì°¸ê³  ë¬¸ì„œ:
- ARCHITECTURE.md: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- IMPLEMENTATION_GUIDE.md: ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- README.md: í”„ë¡œì íŠ¸ ê°œìš”


âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì´ íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ê°€ì´ë“œì¼ ë¿ì…ë‹ˆë‹¤
- ììœ ë¡­ê²Œ ì¬ì„¤ê³„í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë‹¨, generate_response() í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
  (app.pyì—ì„œ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸)
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import json

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
BASE_DIR = Path(__file__).resolve().parent.parent


class ChatbotService:
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì±—ë´‡ì˜ ëª¨ë“  AI ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì±…ì„:
    1. OpenAI API ê´€ë¦¬
    2. ChromaDB ë²¡í„° ê²€ìƒ‰
    3. LangChain ë©”ëª¨ë¦¬ ê´€ë¦¬
    4. ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸
    
    ì§ì ‘ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ:
    - __init__: ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    - _load_config: ì„¤ì • íŒŒì¼ ë¡œë“œ
    - _init_chromadb: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    - _create_embedding: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
    - _search_similar: RAG ê²€ìƒ‰ ìˆ˜í–‰ (í•µì‹¬!)
    - _build_prompt: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - generate_response: ìµœì¢… ì‘ë‹µ ìƒì„± (ëª¨ë“  ë¡œì§ í†µí•©)
    """
    
    def __init__(self):
        """
        ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        TODO: ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë“¤ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”

        1. Config ë¡œë“œ
           - config/chatbot_config.json íŒŒì¼ ì½ê¸°
           - ì±—ë´‡ ì´ë¦„, ì„¤ëª…, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë“±

        2. OpenAI Client
           - API í‚¤: os.getenv("OPENAI_API_KEY")
           - from openai import OpenAI
           - self.client = OpenAI(api_key=...)

        3. ChromaDB
           - í…ìŠ¤íŠ¸ ì„ë² ë”© ì»¬ë ‰ì…˜ ì—°ê²°
           - ê²½ë¡œ: static/data/chatbot/chardb_embedding
           - self.collection = ...

        4. LangChain Memory (ì„ íƒ)
           - ConversationSummaryBufferMemory
           - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
           - self.memory = ...

        íŒíŠ¸:
        - ChromaDB: import chromadb
        - LangChain: from langchain.memory import ConversationSummaryBufferMemory
        """
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘... ")

        # 1. Config ë¡œë“œ
        self.config = self._load_config()
        print(f"[ChatbotService] Config ë¡œë“œ ì™„ë£Œ: {self.config.get('name', 'Unknown')}")

        # 2. OpenAI API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 3. ChatOpenAI (LangChain) ì´ˆê¸°í™”
        from langchain_openai import ChatOpenAI
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=500,
            api_key=api_key
        )
        print("[ChatbotService] ChatOpenAI (LangChain) ì´ˆê¸°í™” ì™„ë£Œ")

        # 4. OpenAI Client ì´ˆê¸°í™” (ì„ë² ë”©ìš©)
        from openai import OpenAI
        self.client = OpenAI(api_key=api_key)
        print("[ChatbotService] OpenAI Client ì´ˆê¸°í™” ì™„ë£Œ")

        # 5. ChromaDB ì´ˆê¸°í™”
        try:
            self.collection = self._init_chromadb()
            print(f"[ChatbotService] ChromaDB ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"[ChatbotService] ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨ (ì»¬ë ‰ì…˜ì´ ì—†ì„ ìˆ˜ ìˆìŒ): {e}")
            self.collection = None

        # 6. ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ ì´ˆê¸°í™” (InMemoryChatMessageHistory)
        from langchain_core.chat_history import InMemoryChatMessageHistory

        # ê° ì‚¬ìš©ì(session_id)ë³„ë¡œ ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        self.store = {}

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
        def get_session_history(session_id: str) -> InMemoryChatMessageHistory:
            if session_id not in self.store:
                self.store[session_id] = InMemoryChatMessageHistory()
            return self.store[session_id]

        self.get_session_history = get_session_history
        print("[ChatbotService] ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ")

        # 7. ê²Œì„ ìƒíƒœ ê´€ë¦¬ì ì´ˆê¸°í™”
        from .game_state_manager import GameStateManager
        save_dir = BASE_DIR / "static" / "data" / "game_states"
        self.game_manager = GameStateManager(save_dir)
        print("[ChatbotService] ê²Œì„ ìƒíƒœ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")

        # 8. ì´ë²¤íŠ¸ ê°ì§€ê¸° ì´ˆê¸°í™”
        from .event_detector import EventDetector
        self.event_detector = EventDetector(self.llm)
        print("[ChatbotService] ì´ë²¤íŠ¸ ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

        # 9. ìŠ¤íƒ¯ ê³„ì‚°ê¸° ì´ˆê¸°í™”
        from .stat_calculator import StatCalculator
        self.stat_calculator = StatCalculator(self.llm)
        print("[ChatbotService] ìŠ¤íƒ¯ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ")
    
    
    def _load_config(self):
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ

        TODO: config/chatbot_config.json ì½ì–´ì„œ ë°˜í™˜

        ë°˜í™˜ê°’ ì˜ˆì‹œ:
        {
            "name": "ê¹€ì„œê°•",
            "character": {...},
            "system_prompt": {...}
        }
        """
        config_path = BASE_DIR / "config" / "chatbot_config.json"

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"[WARNING] Config ë¡œë“œ ì‹¤íŒ¨ ({type(e).__name__}): {e}")
            print(f"[WARNING] ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
            return {
                "name": "ì±—ë´‡",
                "description": "ê¸°ë³¸ ì±—ë´‡ì…ë‹ˆë‹¤.",
                "system_prompt": {
                    "base": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
                    "rules": ["ì¹œì ˆí•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”"]
                }
            }
    
    
    def _init_chromadb(self):
        """
        ChromaDB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ë°˜í™˜

        TODO:
        1. PersistentClient ìƒì„±
        2. ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì´ë¦„: "rag_collection")
        3. ì»¬ë ‰ì…˜ ë°˜í™˜

        íŒíŠ¸:
        - import chromadb
        - db_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
        - client = chromadb.PersistentClient(path=str(db_path))
        - collection = client.get_collection(name="rag_collection")
        """
        import chromadb

        # ChromaDB ì €ì¥ ê²½ë¡œ
        db_path = BASE_DIR / "static" / "data" / "chatbot" / "chardb_embedding"

        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        db_path.mkdir(parents=True, exist_ok=True)

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = chromadb.PersistentClient(path=str(db_path))

        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
        try:
            collection = client.get_collection(name="rag_collection")
            print(f"[ChromaDB] ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: rag_collection (ë¬¸ì„œ ìˆ˜: {collection.count()})")
        except Exception:
            # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            collection = client.create_collection(
                name="rag_collection",
                metadata={"description": "RAGìš© í…ìŠ¤íŠ¸ ì„ë² ë”© ì»¬ë ‰ì…˜"}
            )
            print("[ChromaDB] ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: rag_collection")

        return collection
    
    
    def _create_embedding(self, text: str) -> list:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

        Args:
            text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            list: 3072ì°¨ì› ë²¡í„° (text-embedding-3-large ëª¨ë¸)

        TODO:
        1. OpenAI API í˜¸ì¶œ
        2. embeddings.create() ì‚¬ìš©
        3. ë²¡í„° ë°˜í™˜

        íŒíŠ¸:
        - response = self.client.embeddings.create(
        -     input=[text],
        -     model="text-embedding-3-large"
        - )
        - return response.data[0].embedding
        """
        response = self.client.embeddings.create(
            input=[text],
            model="text-embedding-3-large"
        )
        return response.data[0].embedding
    
    
    def _search_similar(self, query: str, session_id: str, threshold: float = 0.45, top_k: int = 5):
        """
        RAG ê²€ìƒ‰: ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸° (í•µì‹¬ ë©”ì„œë“œ!)

        Args:
            query (str): ê²€ìƒ‰ ì§ˆì˜
            threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0.3-0.5 ê¶Œì¥)
            top_k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜

        Returns:
            tuple: (document, similarity, metadata) ë˜ëŠ” (None, None, None)

        TODO: RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

        1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
           query_embedding = self._create_embedding(query)

        2. ChromaDB ê²€ìƒ‰
           results = self.collection.query(
               query_embeddings=[query_embedding],
               n_results=top_k,
               include=["documents", "distances", "metadatas"]
           )

        3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
           for doc, dist, meta in zip(...):
               similarity = 1 / (1 + dist)  â† ìœ ì‚¬ë„ ê³µì‹!
               if similarity >= threshold:
                   ...

        4. ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜
           return (best_document, best_similarity, metadata)


        ğŸ’¡ í•µì‹¬ ê°œë…:

        - Distance vs Similarity
          Â· ChromaDBëŠ” "ê±°ë¦¬(distance)"ë¥¼ ë°˜í™˜ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
          Â· ìš°ë¦¬ëŠ” "ìœ ì‚¬ë„(similarity)"ë¡œ ë³€í™˜ (í´ìˆ˜ë¡ ìœ ì‚¬)
          Â· ë³€í™˜ ê³µì‹: similarity = 1 / (1 + distance)

        - Threshold
          Â· 0.3: ë§¤ìš° ëŠìŠ¨í•œ ë§¤ì¹­ (ê´€ë ¨ì„± ë‚®ì•„ë„ OK)
          Â· 0.45: ì ë‹¹í•œ ë§¤ì¹­ (ì¶”ì²œ!)
          Â· 0.7: ë§¤ìš° ì—„ê²©í•œ ë§¤ì¹­ (ì •í™•í•œ ë‹µë§Œ)

        - Top K
          Â· 5-10ê°œ ì •ë„ ê²€ìƒ‰
          Â· ê·¸ ì¤‘ threshold ë„˜ëŠ” ê²ƒë§Œ ì‚¬ìš©


        ğŸ› ë””ë²„ê¹… íŒ:
        - print()ë¡œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        - ìœ ì‚¬ë„ ê°’ í™•ì¸ (ë„ˆë¬´ ë‚®ìœ¼ë©´ threshold ì¡°ì •)
        - ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í™•ì¸
        """
        # ChromaDB ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ None ë°˜í™˜
        if self.collection is None or self.collection.count() == 0:
            print("[RAG] ChromaDB ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤.")
            return (None, None, None)

        # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self._create_embedding(query)

        # 2. ChromaDB ê²€ìƒ‰ (where í•„í„° ì ìš©)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "distances", "metadatas"]
        )

        # 3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
        if not results['documents'] or not results['documents'][0]:
            print(f"[RAG] âœ— ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return (None, None, None)
            
        documents = results['documents'][0]
        distances = results['distances'][0]
        metadatas = results['metadatas'][0] if results['metadatas'] and results['metadatas'][0] else [{}] * len(documents)

        best_document = None
        best_similarity = 0
        best_metadata = None

        for doc, dist, meta in zip(documents, distances, metadatas):
            similarity = 1 / (1 + dist)
            print(f"[RAG] ë¬¸ì„œ: {doc[:50]}... | ê±°ë¦¬: {dist:.4f} | ìœ ì‚¬ë„: {similarity:.4f}")

            if similarity >= threshold and similarity > best_similarity:
                best_document = doc
                best_similarity = similarity
                best_metadata = meta

        if best_document:
            print(f"[RAG] âœ“ ìœ ì‚¬ ë¬¸ì„œ ë°œê²¬ (ìœ ì‚¬ë„: {best_similarity:.4f})")
            return (best_document, best_similarity, best_metadata)
        else:
            print(f"[RAG] âœ— Threshold({threshold}) ì´ìƒì¸ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return (None, None, None)
    # <<< ìˆ˜ì • ë >>>
    
    
    def _build_prompt(self, context: str = None, session_id: str = None):
        """
        LangChain ChatPromptTemplate êµ¬ì„±

        Args:
            context (str): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒ)
            session_id (str): ì‚¬ìš©ì ì„¸ì…˜ ID (ê²Œì„ ìƒíƒœ ë¡œë“œìš©)

        Returns:
            ChatPromptTemplate: LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

        ì„¤ëª…:
        - SystemMessage: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ê²Œì„ ìƒíƒœ + RAG ì»¨í…ìŠ¤íŠ¸
        - MessagesPlaceholder: ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ì‚½ì… (RunnableWithMessageHistoryê°€ ì²˜ë¦¬)
        - HumanMessage: ì‚¬ìš©ì ì…ë ¥
        """
        from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

        system_parts = []
        
        if session_id:
            game_state = self.game_manager.get_or_create(session_id)

            system_prompt_config = self.config.get('system_prompt', {})
            base_prompt = system_prompt_config.get('base', 'ë‹¹ì‹ ì€ ì„œê°•íƒœì…ë‹ˆë‹¤.')
            rules = system_prompt_config.get('rules', [])
            system_parts.append(base_prompt)
            if rules:
                system_parts.append("\n[ëŒ€í™” ê·œì¹™]")
                for rule in rules:
                    system_parts.append(f"- {rule}")
            
            # AIì—ê²Œ ì „ë‹¬í•  ìŠ¤íƒ¯ ì •ë³´ë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ìˆ˜ì •
            state_info = f"""

[í˜„ì¬ ê²Œì„ ìƒíƒœ]
- í˜„ì¬ ì‹œì : {game_state.current_month}ì›”
- ì¹œë°€ë„: {game_state.stats.intimacy}/100
- ë©˜íƒˆ: {game_state.stats.mental}/100
- ì²´ë ¥: {game_state.stats.stamina}/100
- íƒ€ê²©: {game_state.stats.batting}/100
- ì£¼ë£¨: {game_state.stats.speed}/100
- ìˆ˜ë¹„: {game_state.stats.defense}/100

[ìºë¦­í„° í–‰ë™ ê°€ì´ë“œ]
{self._get_behavior_guide(game_state)}
"""
            system_parts.append(state_info)

        # 3. RAG ê²€ìƒ‰ ê²°ê³¼(context)ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        if context:
            system_parts.append(f"\n[ì°¸ê³  ì •ë³´]\n{context}")

        system_message = "\n".join(system_parts)

        # 4. ìµœì¢… ChatPromptTemplate ìƒì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")
        ])

        return prompt
    # <<< ìˆ˜ì • ë >>>


    def _get_behavior_guide(self, game_state) -> str:
        """
        ì¹œë°€ë„ì— ë”°ë¥¸ ìºë¦­í„° í–‰ë™ ê°€ì´ë“œ

        Args:
            game_state: GameState ê°ì²´

        Returns:
            í–‰ë™ ê°€ì´ë“œ ë¬¸ìì—´
        """
        intimacy = game_state.stats.intimacy

        if intimacy < 30:
            return """ì°¨ê°‘ê³  í‹±í‹±ëŒ€ëŠ” ë§íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
ì½”ì¹˜ì—ê²Œ ë°©ì–´ì ì´ê³  ê±°ë¦¬ë¥¼ ë‘¡ë‹ˆë‹¤.
ì‹¸ê°€ì§€ ìˆì–´ ë³´ì´ì§€ë§Œ, ì™„ì „íˆ ë¬´ë¡€í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.
ì§§ê³  í‰ëª…ìŠ¤ëŸ¬ìš´ ëŒ€ë‹µì„ ì„ í˜¸í•©ë‹ˆë‹¤."""
        elif intimacy < 60:
            return """ì¡°ê¸ˆì”© ë§ˆìŒì„ ì—´ê¸° ì‹œì‘í•©ë‹ˆë‹¤.
ê°€ë” ì†”ì§í•œ ê°ì •ì„ í‘œí˜„í•˜ì§€ë§Œ ì—¬ì „íˆ ì¡°ì‹¬ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.
ì½”ì¹˜ì˜ ë§ì— ê·€ë¥¼ ê¸°ìš¸ì´ê¸° ì‹œì‘í•˜ì§€ë§Œ ì‰½ê²Œ ì¸ì •í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤."""
        else:
            return """í˜‘ì¡°ì ì´ê³  ë”°ëœ»í•œ íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤.
ì½”ì¹˜ë¥¼ ì‹ ë¢°í•˜ê³  ì¡´ì¤‘í•˜ë©°, ì ê·¹ì ìœ¼ë¡œ ëŒ€í™”ì— ì°¸ì—¬í•©ë‹ˆë‹¤.
ì•¼êµ¬ì— ëŒ€í•œ ì—´ì •ì„ ì†”ì§í•˜ê²Œ ë“œëŸ¬ëƒ…ë‹ˆë‹¤."""


    def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì") -> dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„± (LangChain LCEL ê¸°ë°˜)

        Args:
            user_message (str): ì‚¬ìš©ì ì…ë ¥
            username (str): ì‚¬ìš©ì ì´ë¦„ (session_idë¡œë„ ì‚¬ìš©ë¨)

        Returns:
            dict: {
                'reply': str,       # ì±—ë´‡ ì‘ë‹µ í…ìŠ¤íŠ¸
                'image': str|None   # ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒ)
            }


        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“‹ LangChain LCEL íŒŒì´í”„ë¼ì¸
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
            - "init" ë©”ì‹œì§€ëŠ” ì¸ì‚¬ë§ ë°˜í™˜

        [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
            - ChromaDBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            - ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨

        [3ë‹¨ê³„] ChatPromptTemplate êµ¬ì„±
            - SystemMessage + RAG ì»¨í…ìŠ¤íŠ¸
            - MessagesPlaceholder (ëŒ€í™” íˆìŠ¤í† ë¦¬)
            - HumanMessage (ì‚¬ìš©ì ì…ë ¥)

        [4ë‹¨ê³„] LCEL ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
            - prompt | self.llm (íŒŒì´í”„ ì—°ì‚°ì)
            - RunnableWithMessageHistoryë¡œ ë˜í•‘
            - session_id=usernameìœ¼ë¡œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

        [5ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
            - AIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ì €ì¥ë¨ (RunnableWithMessageHistoryê°€ ì²˜ë¦¬)


        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ’¡ í•µì‹¬ ë³€ê²½ì‚¬í•­
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        1. OpenAI API ì§ì ‘ í˜¸ì¶œ â†’ LangChain ChatOpenAI ì‚¬ìš©
        2. ìˆ˜ë™ ë©”ëª¨ë¦¬ ê´€ë¦¬ â†’ RunnableWithMessageHistory ìë™ ê´€ë¦¬
        3. ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ â†’ ChatPromptTemplate ì‚¬ìš©
        4. ëª…ë ¹í˜• â†’ ì„ ì–¸í˜• (LCEL)
        """
        print(f"\n{'='*50}")
        print(f"[USER] {username}: {user_message}")
        try:

            game_state = self.game_manager.get_or_create(username)
            conversation_history = self.get_session_history(username).messages
            event_info = self.event_detector.check_event(
                game_state=game_state,
                conversation_history=conversation_history
            )

            if event_info and event_info['event_key'] == '5ì›”_ê°ˆë“±':
                print(f"[EVENT] 5ì›” ë©”ì¸ ì´ë²¤íŠ¸ ë°œìƒ! ìŠ¤í† ë¦¬ë¶ '5_main_event'ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤.")
                game_state.flags['backstory_revealed'] = True
                game_state.stats.apply_changes({"intimacy": 10})
                self.game_manager.save(username)
                
                return {
                    'reply': event_info['trigger_message'],
                    'storybook_id': '5_main_event'
                }

            if user_message.strip().lower() == "init":
                bot_name = self.config.get('name', 'ì±—ë´‡')
                greeting = "ì™œ ì˜¤ì…¨ì–´ìš”. ì•Œì•„ì„œ í›ˆë ¨í•˜ê² ë‹¤ê³  ë§ì”€ë“œë ¸ì–ì•„ìš”."
                print(f"[BOT] (ì´ˆê¸° ì¸ì‚¬) {greeting}")
                print(f"{'='*50}\n")
                return {
                    'reply': greeting,
                    'image': None
                }

            # [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
            # <<< ìˆ˜ì • ì‹œì‘: _search_similar í•¨ìˆ˜ í˜¸ì¶œ ì‹œ session_id(username) ì „ë‹¬ >>>
            # ìˆ˜ì •ëœ _search_similar í•¨ìˆ˜ê°€ ëŒ€í™” ëª¨ë“œë¥¼ í™•ì¸í•˜ë ¤ë©´ ì´ ì •ë³´ê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.
            context, similarity, metadata = self._search_similar(
                query=user_message,
                session_id=username,
                threshold=0.45,
                top_k=5
            )
            # <<< ìˆ˜ì • ë >>>

            has_context = (context is not None)

            # ë””ë²„ê¹… ì¶œë ¥
            if has_context:
                print(f"[RAG] âœ“ Context found (ìœ ì‚¬ë„: {similarity:.4f})")
                print(f"[RAG] Context preview: {context[:100]}...")
            else:
                print(f"[RAG] âœ— No context found (ì¼ë°˜ ëŒ€í™” ëª¨ë“œ)")

            # [3ë‹¨ê³„] ChatPromptTemplate êµ¬ì„± (ê²Œì„ ìƒíƒœ í¬í•¨)
            prompt = self._build_prompt(context=context, session_id=username)

            # [4ë‹¨ê³„] LCEL ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
            print(f"[LLM] Building LangChain LCEL pipeline...")

            # LCEL: prompt | llm (íŒŒì´í”„ ì—°ì‚°ìë¡œ ì²´ì¸ êµ¬ì„±)
            chain = prompt | self.llm

            # RunnableWithMessageHistoryë¡œ ë˜í•‘ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬)
            from langchain_core.runnables.history import RunnableWithMessageHistory

            chain_with_history = RunnableWithMessageHistory(
                chain,
                self.get_session_history,
                input_messages_key="input",
                history_messages_key="history"
            )

            # ì²´ì¸ ì‹¤í–‰ (session_idë¡œ username ì‚¬ìš©)
            print(f"[LLM] Invoking chain with session_id='{username}'...")
            response = chain_with_history.invoke(
                {"input": user_message},
                config={"configurable": {"session_id": username}}
            )

            # AIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            reply = response.content

            print(f"[LLM] âœ“ Response generated")
            print(f"[BOT] {reply[:100]}...")
            print(f"[MEMORY] âœ“ Conversation automatically saved to session '{username}'")

            # [5ë‹¨ê³„] ìŠ¤íƒ¯ ë³€í™” ê³„ì‚° ë° ì ìš©
            game_state = self.game_manager.get_or_create(username)

            # ì´ì „ ìŠ¤íƒ¯ ì €ì¥ (ë³€í™”ëŸ‰ ê³„ì‚°ìš©)
            old_stats = game_state.stats.to_dict()

            # LLMìœ¼ë¡œ ìŠ¤íƒ¯ ë³€í™” ë¶„ì„
            stat_changes, stat_reason = self.stat_calculator.analyze_conversation(
                user_message=user_message,
                bot_reply=reply,
                game_state=game_state
            )

            # ìŠ¤íƒ¯ ë³€í™” ì ìš©
            if stat_changes:
                game_state.stats.apply_changes(stat_changes)
                print(f"[STAT] âœ“ Stat changes applied: {stat_changes}")
                print(f"[STAT] Reason: {stat_reason}")
            else:
                print(f"[STAT] No stat changes")

            # [6ë‹¨ê³„] ê²Œì„ ìƒíƒœ ì €ì¥
            self.game_manager.save(username)
            print(f"[GAME] âœ“ Game state saved for '{username}'")

            # [7ë‹¨ê³„] ì´ë²¤íŠ¸ ê°ì§€ ë° íŒíŠ¸ ì œê³µ
            conversation_history = self.get_session_history(username).messages

            # ì´ë²¤íŠ¸ ì²´í¬
            event_info = self.event_detector.check_event(
                game_state=game_state,
                conversation_history=conversation_history,
                recent_messages=10
            )

            # íŒíŠ¸ ì²´í¬ (5ë²ˆ ì´ìƒ ëŒ€í™”í–ˆì„ ë•Œ)
            hint = None
            if len(conversation_history) >= 5:
                hint = self.event_detector.get_hint(
                    game_state=game_state,
                    conversation_history=conversation_history,
                    stuck_threshold=5
                )

            if event_info:
                print(f"[EVENT] âœ“ Event triggered: {event_info['event_name']}")
            if hint:
                print(f"[HINT] âœ“ Hint provided: {hint}")

            # [8ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜ (ë””ë²„ê·¸ ì •ë³´ í¬í•¨)
            print(f"{'='*50}\n")

            # ê¸°ë³¸ ì‘ë‹µ
            response_dict = {
                'reply': reply,
                'image': None
            }

            # <<< ìˆ˜ì • ì‹œì‘: _search_similar í•¨ìˆ˜ì— session_id(username) ì „ë‹¬ >>>
            # 'ì–´ë¨¸ë‹ˆ ëŒ€í™” ëª¨ë“œ'ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
            context, similarity, metadata = self._search_similar(
                query=user_message,
                session_id=username, # <<< ìˆ˜ì •: session_id ì „ë‹¬
                threshold=0.45,
                top_k=5
            )
            # <<< ìˆ˜ì • ë >>>

            # ì´ë²¤íŠ¸ ì •ë³´ ì¶”ê°€ (ìˆì„ ê²½ìš°)
            if event_info:
                response_dict['event'] = event_info

            # íŒíŠ¸ ì¶”ê°€ (ìˆì„ ê²½ìš°)
            if hint:
                response_dict['hint'] = hint

            # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€ (ê°œë°œ ëª¨ë“œ)
            response_dict['debug'] = {
                'game_state': {
                    'current_month': game_state.current_month,
                    'current_day': game_state.current_day,
                    'stats': game_state.stats.to_dict(),
                    'intimacy_level': self.stat_calculator.get_intimacy_level(game_state.stats.intimacy),
                    'months_until_draft': game_state.get_months_until_draft(),
                },
                'stat_changes': {
                    'changes': stat_changes,
                    'reason': stat_reason,
                    'old_stats': old_stats,
                    'new_stats': game_state.stats.to_dict()
                },
                'event_check': {
                    'triggered': event_info is not None,
                    'event_name': event_info['event_name'] if event_info else None
                },
                'hint_provided': hint is not None,
                'conversation_count': len(conversation_history),
                'event_history': game_state.event_history
            }

            return response_dict

        except Exception as e:
            print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            print(f"{'='*50}\n")
            return {
                'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'image': None
            }

    def generate_response_stream(self, user_message: str, username: str = "ì‚¬ìš©ì"):
        """
        LangChain ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì‘ë‹µ ìƒì„±

        Args:
            user_message (str): ì‚¬ìš©ì ì…ë ¥
            username (str): ì‚¬ìš©ì ì´ë¦„ (session_idë¡œë„ ì‚¬ìš©ë¨)

        Yields:
            dict: ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë°ì´í„°
                - type: 'token' | 'metadata' | 'error' | 'done'
                - content: í† í° í…ìŠ¤íŠ¸ ë˜ëŠ” ë©”íƒ€ë°ì´í„°
        """
        print(f"\n{'='*50}")
        print(f"[USER] {username}: {user_message} (STREAMING)")

        try:
            game_state = self.game_manager.get_or_create(username)
            conversation_history = self.get_session_history(username).messages
            event_info = self.event_detector.check_event(
                game_state=game_state,
                conversation_history=conversation_history
            )

            if event_info and event_info['event_key'] == '5ì›”_ê°ˆë“±':
                print(f"[EVENT] 5ì›” ë©”ì¸ ì´ë²¤íŠ¸ ë°œìƒ! (ìŠ¤íŠ¸ë¦¼)")
                game_state.flags['backstory_revealed'] = True
                game_state.stats.apply_changes({"intimacy": 10})
                self.game_manager.save(username)

                response_dict = {
                    'reply': event_info['trigger_message'],
                    'storybook_id': '5_main_event'
                }
                yield {'type': 'full_response', 'content': response_dict}
                yield {'type': 'done', 'content': ''}
                return # ì—¬ê¸°ì„œ í•¨ìˆ˜ ì¢…ë£Œ

            # [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
            if user_message.strip().lower() == "init":
                bot_name = self.config.get('name', 'ì±—ë´‡')
                greeting = "ì™œ ì˜¤ì…¨ì–´ìš”. ì•Œì•„ì„œ í›ˆë ¨í•˜ê² ë‹¤ê³  ë§ì”€ë“œë ¸ì–ì•„ìš”."
                print(f"[BOT] (ì´ˆê¸° ì¸ì‚¬) {greeting}")
                print(f"{'='*50}\n")

                # ì´ˆê¸° ì¸ì‚¬ëŠ” í•œë²ˆì— ì „ì†¡
                yield {
                    'type': 'token',
                    'content': greeting
                }
                yield {
                    'type': 'done',
                    'content': ''
                }
                return

            # <<< ìˆ˜ì • ì‹œì‘: _search_similar í•¨ìˆ˜ì— session_id(username) ì „ë‹¬ >>>
            context, similarity, metadata = self._search_similar(
                query=user_message,
                session_id=username, # <<< ìˆ˜ì •: session_id ì „ë‹¬
                threshold=0.45,
                top_k=5
            )
            # <<< ìˆ˜ì • ë >>>

            has_context = (context is not None)

            if has_context:
                print(f"[RAG] âœ“ Context found (ìœ ì‚¬ë„: {similarity:.4f})")
            else:
                print(f"[RAG] âœ— No context found (ì¼ë°˜ ëŒ€í™” ëª¨ë“œ)")

            # [3ë‹¨ê³„] ChatPromptTemplate êµ¬ì„±
            prompt = self._build_prompt(context=context, session_id=username)

            # [4ë‹¨ê³„] LCEL ì²´ì¸ êµ¬ì„±
            print(f"[LLM] Building LangChain LCEL streaming pipeline...")

            chain = prompt | self.llm

            from langchain_core.runnables.history import RunnableWithMessageHistory

            chain_with_history = RunnableWithMessageHistory(
                chain,
                self.get_session_history,
                input_messages_key="input",
                history_messages_key="history"
            )

            # [5ë‹¨ê³„] ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            print(f"[LLM] Starting stream with session_id='{username}'...")

            full_response = ""  # ì „ì²´ ì‘ë‹µ ìˆ˜ì§‘ (ìŠ¤íƒ¯ ê³„ì‚°ìš©)

            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í† í° ìƒì„±
            for chunk in chain_with_history.stream(
                {"input": user_message},
                config={"configurable": {"session_id": username}}
            ):
                # AIMessage ë˜ëŠ” AIMessageChunkì—ì„œ content ì¶”ì¶œ
                if hasattr(chunk, 'content'):
                    token = chunk.content
                    if token:  # ë¹ˆ í† í° í•„í„°ë§
                        full_response += token
                        yield {
                            'type': 'token',
                            'content': token
                        }

            print(f"[LLM] âœ“ Stream completed")
            print(f"[BOT] {full_response[:100]}...")
            print(f"[MEMORY] âœ“ Conversation automatically saved to session '{username}'")

            # [6ë‹¨ê³„] ìŠ¤íƒ¯ ë³€í™” ê³„ì‚° ë° ì ìš©
            game_state = self.game_manager.get_or_create(username)
            old_stats = game_state.stats.to_dict()

            stat_changes, stat_reason = self.stat_calculator.analyze_conversation(
                user_message=user_message,
                bot_reply=full_response,
                game_state=game_state
            )

            if stat_changes:
                game_state.stats.apply_changes(stat_changes)
                print(f"[STAT] âœ“ Stat changes applied: {stat_changes}")
            else:
                print(f"[STAT] No stat changes")

            # [7ë‹¨ê³„] ê²Œì„ ìƒíƒœ ì €ì¥
            self.game_manager.save(username)
            print(f"[GAME] âœ“ Game state saved for '{username}'")

            # [8ë‹¨ê³„] ì´ë²¤íŠ¸ ê°ì§€ ë° íŒíŠ¸ ì œê³µ
            conversation_history = self.get_session_history(username).messages

            event_info = self.event_detector.check_event(
                game_state=game_state,
                conversation_history=conversation_history,
                recent_messages=10
            )

            hint = None
            if len(conversation_history) >= 5:
                hint = self.event_detector.get_hint(
                    game_state=game_state,
                    conversation_history=conversation_history,
                    stuck_threshold=5
                )

            if event_info:
                print(f"[EVENT] âœ“ Event triggered: {event_info['event_name']}")
            if hint:
                print(f"[HINT] âœ“ Hint provided: {hint}")

            # [9ë‹¨ê³„] ë©”íƒ€ë°ì´í„° ì „ì†¡
            print(f"{'='*50}\n")

            metadata = {
                'debug': {
                    'game_state': {
                        'current_month': game_state.current_month,
                        'current_day': game_state.current_day,
                        'stats': game_state.stats.to_dict(),
                        'intimacy_level': self.stat_calculator.get_intimacy_level(game_state.stats.intimacy),
                        'months_until_draft': game_state.get_months_until_draft(),
                    },
                    'stat_changes': {
                        'changes': stat_changes,
                        'reason': stat_reason,
                        'old_stats': old_stats,
                        'new_stats': game_state.stats.to_dict()
                    },
                    'event_check': {
                        'triggered': event_info is not None,
                        'event_name': event_info['event_name'] if event_info else None
                    },
                    'hint_provided': hint is not None,
                    'conversation_count': len(conversation_history),
                    'event_history': game_state.event_history
                }
            }

            if event_info:
                metadata['event'] = event_info
            if hint:
                metadata['hint'] = hint

            yield {
                'type': 'metadata',
                'content': metadata
            }

            # [10ë‹¨ê³„] ì™„ë£Œ ì‹ í˜¸
            yield {
                'type': 'done',
                'content': ''
            }

        except Exception as e:
            print(f"[ERROR] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            print(f"{'='*50}\n")

            yield {
                'type': 'error',
                'content': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            }


# ============================================================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================================================
# ChatbotService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì•± ì „ì²´ì—ì„œ ì¬ì‚¬ìš©
# (ë§¤ë²ˆ ìƒˆë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì )

_chatbot_service = None

def get_chatbot_service():
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    ì²« í˜¸ì¶œ ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì´í›„ ì¬ì‚¬ìš©
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = ChatbotService()
    return _chatbot_service


# ============================================================================
# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# ============================================================================

if __name__ == "__main__":
    """
    ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    ì‹¤í–‰ ë°©ë²•:
    python services/chatbot_service.py
    """
    print("ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    service = get_chatbot_service()
    
    # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("init", "í…ŒìŠ¤í„°")
    print(f"ì´ˆê¸° ì‘ë‹µ: {response}")
    
    # ì¼ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("ì•ˆë…•í•˜ì„¸ìš”!", "í…ŒìŠ¤í„°")
    print(f"ì‘ë‹µ: {response}")
